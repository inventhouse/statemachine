#!/usr/bin/env python3
# Copyright (c) 2019-2020 Benjamin Holt -- MIT License

"""
Statemachine Line EDitor
or: Sed-Like EDitor

Like `sed` but using statemachine-based rules instead of imperative commands.
"""
import argparse
from functools import lru_cache
import re
import shutil
import subprocess as sub
import sys
import textwrap

import statemachine as sm
#####


###  Main  ###
def main(args, env, stdin):
    description = "Statemachine Line EDitor, like `sed` but built with statemachine rules (v1.0)"
    epilog = textwrap.dedent("""\
    Rules can be created with -r/--named-rules and start with a delimiter character of our choice follwed by 7 fields:

        :name:test:arg:dst:action:arg:tag

    Rules are added to states in the underlying statemachine with -a/--add-rules, and may be either named or anonymous:

        :state:name:tag
        :state:test:arg:dst:action:arg:tag

    Unnecessary fields may be omitted from the end in all cases, and 'test' and 'action' commands are not case-sensitive.  Rules with no 'state' specified are implicitly added to all states, but evaluated after any explicit rules; rules with no 'dst' remain in the same state ("self-transition")

    More documentation and examples in sled.md:
    https://github.com/inventhouse/statemachine/blob/master/sled.md
    """)

    arg_parser = argparse.ArgumentParser(
        description=wrapper(description, width=75),
        epilog=wrapper(epilog, width=75),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    # arg_parser.add_argument(
    #     "in_file",
    #     nargs="?",
    #     metavar="FILE",
    #     help="File to parse, defaults to stdin.",
    # )
    arg_parser.add_argument(
        "-s", "--start",
        default="start",
        metavar="STATE",
        help="Start the parser in STATE, defaults to 'start'.",
    )
    arg_parser.add_argument(
        "-r", "--named-rules",
        nargs="+",
        default=[],
        metavar="RULE",
        help="Define named rules to be added to states below",
    )
    arg_parser.add_argument(
        "-a", "--add-rules",
        nargs="+",
        default=[],
        metavar="RULE",
        help="Add rules to the statemachine.",
    )
    # arg_parser.add_argument(
    #     "-c", "--strip-comments",
    #     action="store_true",
    #     # const=(None, sm.true_test, None, None, "StripComments"),
    #     # default=None,
    #     help="Add a StripComments rule to scrub #-style comments; must be explicitly added to states to raise its priority."
    # )
    arg_parser.add_argument(
        "-d", "--drop-all",
        dest="default_rule",
        action="store_const",
        const=(None, "T", None, None, None, None, "DropAll"),
        default=None,
        help="Add a final DropAll rule to drop any input not handled."
    )
    arg_parser.add_argument(
        "-p", "--pass-all",
        dest="default_rule",
        action="store_const",
        const=(None, "T", None, None, "I", None, "PassAll"),
        default=None,
        help="Add a final PassAll rule to pass any input not handled."
    )
    arg_parser.add_argument(
        "-f", "--rules-file",
        metavar="FILE",
        help="A file of rules for the statemachine.",
    )
    arg_parser.add_argument(
        "-t", "--trace",
        nargs="?",
        default=None,
        const="T> ",
        metavar="N|PREFIX",
        help="An integer will set the default tracing depth, negative means unlimited.  Otherwise, add a verbose trace to the statemachine; trace lines will start with PREFIX, by default 'T> '.",
    )
    arg_parser.add_argument(
        "--more-help",
        action="store_true",
        help="Print help about the available tests and actions.",
    )
    arg_parser.add_argument(
        "--style-help",
        action="store_true",
        help="Print help about the available text styles.",
    )
    arg_parser.add_argument(
        "--print-args",
        action="store_true",
        # help="Print arguments and compiled rules, then exit.",
        help=argparse.SUPPRESS,
    )
    my_args = arg_parser.parse_args(args[1:])

    # named_rules = {}
    # rules = []
    named_lines = []
    add_lines = []
    if my_args.rules_file:
        (named_lines, add_lines) = rules_from_file(my_args.rules_file)

    # if my_args.strip_comments:
    #     named_rules["$StripComments"] = (sm.true_test, None, strip_comments_action, None)
    #     add_lines.append("::StripComments")

    # First parse command-line to lay down any low-level aliases
    named_rules = parse_aliases(my_args.named_rules)

    # Then parse aliases from file
    aliases = parse_aliases(named_lines, existing=named_rules, override = False)  # Don't override the command-line
    named_rules.update(aliases)

    # Finally override any aliases based on the command-line again
    aliases = parse_aliases(my_args.named_rules, existing=named_rules, override = True)
    named_rules.update(aliases)

    # Parse rules
    rules = parse_rules(my_args.add_rules, aliases=named_rules)  # Added rules in args have higher precedence than rules from the file
    rules.extend(parse_rules(add_lines, aliases=named_rules))

    if my_args.default_rule:
        rules.append(my_args.default_rule)

    if my_args.print_args:
        n_str = "\n\t".join(f"{n}: {r}" for n,r in named_rules.items())
        r_str = "\n\t".join(f"{s}: {r}" for s,*r in rules)
        print(f"* Args:\n\t{my_args}\n* Named Rules:\n\t{n_str}\n* Rules:\n\t{r_str}")
        return 0
    if my_args.more_help:
        print(wrapper(f"{helper(Tests)}\n\n{helper(Actions)}", width=75))
        return 0
    if my_args.style_help:
        print(wrapper("In formatting contexts, styles and colors are available as attributes on an object `s`, and usually output should returned to normal with `s.off`, though a couple styles also offer end-codes.  Like this:\n\n\tTo {{s.b}}boldly{{s.off}} go where no one has gone before\n\tTo {s.b}boldly{s.off} go where no one has gone before\n\nText styling varies a lot based on the terminal and settings, and is omitted if the output is redirected.  Here are some examples of their appearance:\n".format(s=style), width=75))
        print(style_helper())
        return 0

    tracer = True  # Use the built-in default tracing
    if my_args.trace:
        try:
            # If int, set trace depth
            tracer = int(my_args.trace)
        except ValueError:
            # Add additional verbose tracing
            tracer = sm.Tracer(printer=my_args.trace)
    parser = sm.StateMachine(my_args.start, tracer=tracer)
    for r in rules:
        # print(r)
        parser.add(*resolve_rule(*r))

    for line in parser.parse( l.rstrip("\n") for l in stdin ):
        print(line)
#####


###  Rule Parsing  ###
def parse_aliases(l, existing=None, override=False):
    "Parse a list of named rule strings into aliases for add-rules"
    if existing is None:
        existing = {}  # {"$name": [fields...], ...}
    aliases = {}  # {"$name": [fields...], ...}

    for s in l:
        name,*fields = split_rule(s)
        assert not name.startswith("$"), f"Rule name '{name}' cannot start with $"

        name = f"${name}"  # All the lookups are way easier if we just work with the $-prefix
        if not override and name in existing:
            continue

        fields = resolve_aliases(fields, aliases, existing)

        # if [ f for f in fields if f is not None and f.startswith("$") and not f.startswith("$$") ]:
        #     # Stash any aliases that did not completely resolve
        #     unresolved[name] = fields
        #     continue

        aliases[name] = fields

    return aliases


def resolve_aliases(fields, *lookups):
    def expand(f):
        for l in lookups:
            if f in l:
                return l[f]
        return [f,]

    expanded = ( expand(f) for f in fields )  # expansion produces list-of-lists
    return [ f for e in expanded for f in e ]  #...then flatten back into a list


def parse_rules(l, aliases=None):
    if aliases is None:
        aliases = {}
    rules = []
    for s in l:
        state,*parts = split_rule(s)
        if len(parts) < 2:  # ensure at least 2 fields
            parts = [*parts, None, None][:2]
        tag = None
        if (len(parts) == 2 and parts[0] is not None and parts[0].startswith("$")):
            # get auto-tag for pure-alias rule
            tag = parts[0].lstrip("$")
            if parts[1] is not None:
                tag = parts[1]
                parts[1] = None  # drop the explicit tag for now

        parts = resolve_aliases(parts, aliases)
        parts = (parts + [None,] * 6)[:6]  # Expand parts to 6 fields
        if tag is not None:
            parts[-1] = tag  # apply saved tag

        rules.append((state, *parts))

    return rules


def resolve_rule(state, test, t_arg, dst, action, a_arg, tag):
    if not test:
        test = "_default"
    l_test = test.lower()
    if l_test not in Tests.__dict__:
        raise KeyError(f"no '{test}' in Tests, run with --more-help for full list")
    test = Tests.__dict__[l_test](t_arg)

    if not action:
        action = "_default"
    l_action = action.lower()
    if l_action not in Actions.__dict__:
        raise KeyError(f"no '{action}' in Actions, run with --more-help for full list")
    action = Actions.__dict__[l_action](a_arg)

    return (state, test, dst, action, tag)


def split_rule(s):
    "Split a rule string based on the inital delimeter"
    d,s = s[0], s[1:]
    parts = [ p if len(p) else None for p in s.split(d) ]
    return parts


class Tests:
    "Tests"
    def t(_):
        ":T::\talways True"
        return sm.true_test

    def l(s):
        ":L:s:\tLiteral string, no string matches empty line"
        # None isn't a thing we'll find in the input lines, test for empty string instead
        return s if s else ""

    def m(s):
        ":M:p:\tMatch a regex pattern"
        return sm.match_test(s)

    def mi(s):
        ":MI:p:\tMatch a regex pattern, ignoring case"
        return sm.match_test(s, flags=re.IGNORECASE)

    def s(s):
        ":S:p:\tSearch for a regex pattern"
        r = re.compile(s)
        def c(i, _):
            return r.search(i)
        return c

    def si(s):
        ":SI:p:\tSearch for a regex pattern, ignoring case"
        r = re.compile(s, flags=re.IGNORECASE)
        def c(i, _):
            return r.search(i)
        return c

    def ceq(n):
        ":CEQ:n:\tinput Count EQuals"
        n = int(n)
        return lambda i, t: t.count == n

    def cgt(n):
        ":CGT:n:\tinput Count Greater-Than"
        n = int(n)
        return lambda i, t: t.count > n

    def clt(n):
        ":CLT:n:\tinput Count Less-Than"
        n = int(n)
        return lambda i, t: t.count < n

    def _default(s):
        "::s:\tdefault test is 'L'"
        return Tests.L(s)


class Actions:
    "Actions"
    def f(s):
        ":F:s:\tFormatted output; input will be passed as 'i', test result will be 'r', 's' can add text styles.  When using styles or colors be sure to include {s.off}"
        return lambda i, t: s.format(i=i, r=t.result, s=style)

    def i(_):
        ":I::\treturn the Input"
        return sm.input_action

    def l(s):
        ":L:s:\tLiteral string"
        # Return empty string instead of None
        return s if s else ""

    def s(s):
        ":S:r:\tSub all occurrences of the test pattern with a replacement; formatting is available in the replacement string as describe above."
        # TODO: assert the result is an re.match
        return lambda i, t: t.result.re.sub(s.format(i=i, r=t.result, s=style), i)

    def _default(s):
        ":::\tdefault action returns no output (drops input)"
        return None


COMMENT_RE = re.compile(r"(^|\s+)#($|[^#].*$)")
DBL_COMMENT_RE = re.compile(r"##")
def strip_comments_action(i, _=None):
    "strip #-style comments and collapse doubled-#"
    s = COMMENT_RE.sub("", i)
    s = DBL_COMMENT_RE.sub("#", s)
    return s
#####


###  Helpers  ###
def wrapper(text, **kwargs):
    "Nothing worse than a bad wrap"
    # Wrap each paragraph separately, then put them back together
    return "\n".join([ textwrap.fill(s, **kwargs) for s in text.splitlines() ])


def rules_from_file(rules_file):
    named_lines = []
    def named(i,t):
        named_lines.append(i)
    add_lines = []
    def add(i,t):
        add_lines.append(i)
    named_section = (
        sm.match_test(r"Named\s*Rules\s*:*", flags=re.IGNORECASE),
        "named", None, "NamedSection"
    )
    add_section = (
        sm.match_test(r"Add\s*Rules\s*:*", flags=re.IGNORECASE),
        "add", None, "AddSection"
    )
    end_section = (
        sm.match_test(r"End\s*Rules\s*:*", flags=re.IGNORECASE),
        "start", None, "EndSection"
    )

    tracer = True
    # tracer = sm.Tracer(printer=lambda s: print(f"T> {s}"))
    categorizer = sm.StateMachine("start", tracer=tracer)
    categorizer.build(
        "named",
        add_section,
        named_section,
        end_section,
        (sm.true_test, None, named, "Named")
    )
    categorizer.build(
        "add",
        add_section,
        named_section,
        end_section,
        (sm.true_test, None, add, "Add")
    )
    categorizer.build(
        None,
        add_section,
        named_section,
        end_section,
        (sm.true_test, None, None, "Drop")
    )
    # print(categorizer.rules)

    with open(rules_file, "r") as rf:
        lines = ( strip_comments_action(l) for l in rf )
        lines = ( l.strip() for l in lines )
        lines = ( l for l in lines if re.search(r"\S", l) )
        # lines = list(lines); print("\n".join(lines), end="")  # join "spends" the generator, convert to list first so it can be iterated again
        for l in lines:
            categorizer.input(l)
    return (named_lines, add_lines)


def helper(cls):
    "Extract doc strings from a class's 'regular' methods to build a help-string"
    keys = sorted([ k for k in cls.__dict__.keys() if not k.startswith("_") ])
    helps = [ (k, cls.__dict__[k].__doc__) for k in keys if cls.__dict__[k].__doc__ ]
    default_key = "_default"
    if default_key in cls.__dict__ and cls.__dict__[default_key].__doc__:
        helps.append(("None", cls.__dict__[default_key].__doc__))
    # help_string = "\n\t".join([ f"{k}:\t{h}" for k,h in helps ])
    help_string = "\n\t".join([ f"{h}" for _,h in helps ])
    return f"{cls.__doc__}:\n\t{help_string}"  # FIXME: wrap helps


def style_helper():
    h = ["Styles:",]
    s = ["{s.b}b|bold{s.off}", "{s.rev}rev{s.off}", "{s.blink}blink{s.off}", "{s.u}u u_off{s.u_off}", "{s.em}em em_off{s.em_off}", "{s.invis}invis{s.off} (invis)"]
    s = [ i.format(s=style) for i in s ]
    h.append("\t" + "  ".join(s))
    h.append("Colors:")
    cl = [ "{{s.{n}}}{n}{{s.off}}".format(n=n).format(s=style) for n in COLOR_NAMES]
    h.append("\t" + "  ".join(cl))
    h.append("Backgrounds:")
    cl = [ "{{s.{n}_bg}}{n}_bg{{s.off}}".format(n=n).format(s=style) for n in COLOR_NAMES]
    h.append("\t" + "  ".join(cl))
    return "\n".join(h)
#####


###  Colors  ###
# Here's a nice tutorial on tput: http://www.linuxcommand.org/lc3_adv_tput.php
def tput_lookup(*cap):
    "Get the value for a capname from tput, see man tput for more information"
    tp_cmd = ["tput",] + [ str(i) for i in cap ]
    result = sub.run(tp_cmd, stdout=sub.PIPE)
    r = ""  # Default to falsey
    if result.returncode == 0:  # If success, capability exists or property is true
        r = result.stdout.decode("utf-8")
        if r:
            try:
                r = int(r)  # Note: many of the int results may change (like cols)
            except ValueError:
                pass  # Nope, not an int
        else:
            r = True  # tput command success means "cap is true"
    return r


def tput_swap(dummy):
    "Decorator to replace a dummy implementation with calls to tput if appropreate and available"
    if sys.stdout.isatty() and shutil.which("tput"):
        return lru_cache()(tput_lookup)  # Note: some attributes (e.g. "cols") can change, so cache may be stale
    else:
        return dummy


@tput_swap
def tput(*cap):
    "Dummy tput implementation, just returns empty string for now"
    return ""  # This might not make much sense for some things (eg "cols"), so callers may need to test and use sensible defaults


class Stylist(object):
    "Map attributes to tput capabilities via aliases dictionaries"
    def __init__(self, *aliases):
        self.aliases = {}
        for d in aliases:
            self.aliases.update(d)

    def __getattr__(self, s):
        if s in self.aliases:
            return tput(*self.aliases[s])
        else:
            return tput(s)


COLOR_NAMES = ("black", "red", "green", "yellow", "blue", "magenta", "cyan", "white")  # REM, supposedly there is an "unused" and "default" after white, but they just seem to wrap
FG_COLORS = { c: ("setaf", n) for n,c in enumerate(COLOR_NAMES) }
BG_COLORS = { f"{c}_bg": ("setab", n) for n,c in enumerate(COLOR_NAMES) }

STYLES = {"off": ("sgr0",), "b": ("bold",), "u": ("smul",), "u_off": ("rmul",), "em": ("smso",), "em_off": ("rmso",),}
style = Stylist(STYLES, FG_COLORS, BG_COLORS)
#####


#####
if __name__ == "__main__":
    import os
    # import sys
    xit = main(sys.argv, os.environ, sys.stdin)
    sys.exit(xit)
#####
